{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcCx2k9nFwm2n5fAteG1HX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rontalapoojareddy/AIAP/blob/main/Aiap_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6pjOz3RzcHz",
        "outputId": "f252e6e8-bb88-4b36-88e7-b47c866c6761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# LAB 17 – AI FOR DATA PROCESSING: CLEANING & PREPROCESSING\n",
        "# ================================================================\n",
        "\n",
        "# ------------------------------------------------\n",
        "# INSTALLATION\n",
        "# ------------------------------------------------\n",
        "!pip install nltk pandas numpy scikit-learn beautifulsoup4 --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ---------------------- TASK 1 ----------------------------------\n",
        "# SOCIAL MEDIA DATA CLEANING\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n==================== TASK 1: SOCIAL MEDIA CLEANING ====================\")\n",
        "\n",
        "# Upload dataset in Google Colab\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "social_df = pd.read_csv(\"social_media.csv\")\n",
        "\n",
        "# ----- BEFORE SUMMARY -----\n",
        "print(\"\\n--- BEFORE CLEANING ---\")\n",
        "print(social_df.head())\n",
        "\n",
        "# -------- REMOVE PUNCTUATION, STOPWORDS, SPECIAL SYMBOLS ----------\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)       # remove punctuation/symbols\n",
        "    words = [w for w in text.split() if w not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "social_df[\"clean_post\"] = social_df[\"post_text\"].apply(clean_text)\n",
        "\n",
        "# -------- HANDLE MISSING VALUES IN likes & shares ----------\n",
        "social_df[\"likes\"] = social_df[\"likes\"].fillna(social_df[\"likes\"].median())\n",
        "social_df[\"shares\"] = social_df[\"shares\"].fillna(0)\n",
        "\n",
        "# -------- TIMESTAMP PROCESSING ----------\n",
        "social_df[\"timestamp\"] = pd.to_datetime(social_df[\"timestamp\"])\n",
        "social_df[\"hour\"] = social_df[\"timestamp\"].dt.hour\n",
        "social_df[\"weekday\"] = social_df[\"timestamp\"].dt.day_name()\n",
        "\n",
        "# -------- REMOVE DUPLICATE / SPAM ----------\n",
        "social_df.drop_duplicates(subset=\"clean_post\", inplace=True)\n",
        "\n",
        "# ----- AFTER SUMMARY -----\n",
        "print(\"\\n--- AFTER CLEANING ---\")\n",
        "print(social_df.head())\n",
        "\n",
        "# -------- TEST CASES ----------\n",
        "assert social_df[\"clean_post\"].isna().sum() == 0\n",
        "assert social_df[\"likes\"].isna().sum() == 0\n",
        "assert \"hour\" in social_df.columns\n",
        "\n",
        "print(\"\\nTask 1 Passed All Tests ✔\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2QUkXov06v3",
        "outputId": "8a6d691a-0ad6-426b-a9d5-8a1a3c384ade"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== TASK 1: SOCIAL MEDIA CLEANING ====================\n",
            "\n",
            "--- BEFORE CLEANING ---\n",
            "   post_id    user                      post_text  likes  shares  \\\n",
            "0        1  user_1  This is a sample POST!!! #fun   20.0     1.0   \n",
            "1        2  user_2        <html>Great Day!</html>   20.0     3.0   \n",
            "2        3  user_3  This is a sample POST!!! #fun   20.0     1.0   \n",
            "3        4  user_4        <html>Great Day!</html>  100.0     NaN   \n",
            "4        5  user_5  This is a sample POST!!! #fun   20.0     5.0   \n",
            "\n",
            "             timestamp  \n",
            "0  2025-01-01 00:00:00  \n",
            "1  2025-01-01 06:00:00  \n",
            "2  2025-01-01 12:00:00  \n",
            "3  2025-01-01 18:00:00  \n",
            "4  2025-01-02 00:00:00  \n",
            "\n",
            "--- AFTER CLEANING ---\n",
            "   post_id    user                      post_text  likes  shares  \\\n",
            "0        1  user_1  This is a sample POST!!! #fun   20.0     1.0   \n",
            "1        2  user_2        <html>Great Day!</html>   20.0     3.0   \n",
            "\n",
            "            timestamp         clean_post  hour    weekday  \n",
            "0 2025-01-01 00:00:00    sample post fun     0  Wednesday  \n",
            "1 2025-01-01 06:00:00  htmlgreat dayhtml     6  Wednesday  \n",
            "\n",
            "Task 1 Passed All Tests ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ---------------------- TASK 2 ----------------------------------\n",
        "# FINANCIAL DATA PREPROCESSING\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n==================== TASK 2: FINANCIAL DATA ====================\")\n",
        "\n",
        "financial_df = pd.read_csv(\"financial_data.csv\")\n",
        "\n",
        "# BEFORE SUMMARY\n",
        "print(\"\\n--- BEFORE ---\")\n",
        "print(financial_df.head())\n",
        "\n",
        "# Missing values\n",
        "financial_df[\"closing_price\"] = financial_df[\"closing_price\"].fillna(method=\"ffill\")\n",
        "financial_df[\"volume\"] = financial_df[\"volume\"].fillna(financial_df[\"volume\"].median())\n",
        "\n",
        "# Lag features\n",
        "financial_df[\"return_1d\"] = financial_df[\"closing_price\"].pct_change()\n",
        "financial_df[\"return_7d\"] = financial_df[\"closing_price\"].pct_change(periods=7)\n",
        "\n",
        "# Log normalize volume\n",
        "financial_df[\"volume_log\"] = np.log1p(financial_df[\"volume\"])\n",
        "\n",
        "# Outlier detection (IQR)\n",
        "Q1 = financial_df[\"closing_price\"].quantile(0.25)\n",
        "Q3 = financial_df[\"closing_price\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "\n",
        "financial_df = financial_df[(financial_df[\"closing_price\"] >= lower) &\n",
        "                            (financial_df[\"closing_price\"] <= upper)]\n",
        "\n",
        "# AFTER SUMMARY\n",
        "print(\"\\n--- AFTER ---\")\n",
        "print(financial_df.head())\n",
        "\n",
        "# TESTS\n",
        "assert financial_df[\"volume\"].isna().sum() == 0\n",
        "assert \"return_1d\" in financial_df.columns\n",
        "assert financial_df[\"volume_log\"].min() >= 0\n",
        "\n",
        "print(\"\\nTask 2 Passed All Tests ✔\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzOGkISs1M9x",
        "outputId": "cec3bc36-09c0-4431-d5d3-a447b2c811b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== TASK 2: FINANCIAL DATA ====================\n",
            "\n",
            "--- BEFORE ---\n",
            "         date  closing_price  volume\n",
            "0  2025-01-01            NaN  5000.0\n",
            "1  2025-01-02         131.04  2000.0\n",
            "2  2025-01-03         138.26  2000.0\n",
            "3  2025-01-04         164.68     NaN\n",
            "4  2025-01-05         165.06  5000.0\n",
            "\n",
            "--- AFTER ---\n",
            "         date  closing_price  volume  return_1d  return_7d  volume_log\n",
            "1  2025-01-02         131.04  2000.0        NaN        NaN    7.601402\n",
            "2  2025-01-03         138.26  2000.0   0.055098        NaN    7.601402\n",
            "3  2025-01-04         164.68  2000.0   0.191089        NaN    7.601402\n",
            "4  2025-01-05         165.06  5000.0   0.002308        NaN    8.517393\n",
            "5  2025-01-06         137.99  1500.0  -0.164001        NaN    7.313887\n",
            "\n",
            "Task 2 Passed All Tests ✔\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-285784354.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  financial_df[\"closing_price\"] = financial_df[\"closing_price\"].fillna(method=\"ffill\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ---------------------- TASK 3 ----------------------------------\n",
        "# IOT SENSOR DATA\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n==================== TASK 3: IOT SENSOR ====================\")\n",
        "\n",
        "iot_df = pd.read_csv(\"iot_sensor.csv\")\n",
        "\n",
        "print(\"\\n--- BEFORE ---\")\n",
        "print(iot_df.head())\n",
        "\n",
        "# Handle missing → Forward fill\n",
        "iot_df[\"temperature\"] = iot_df[\"temperature\"].fillna(method=\"ffill\")\n",
        "iot_df[\"humidity\"] = iot_df[\"humidity\"].fillna(method=\"ffill\")\n",
        "\n",
        "# Remove drift → Rolling mean\n",
        "iot_df[\"temp_smooth\"] = iot_df[\"temperature\"].rolling(5, min_periods=1).mean()\n",
        "iot_df[\"humidity_smooth\"] = iot_df[\"humidity\"].rolling(5, min_periods=1).mean()\n",
        "\n",
        "# Normalize using standard scaling\n",
        "scaler = StandardScaler()\n",
        "iot_df[\"temp_scaled\"] = scaler.fit_transform(iot_df[[\"temp_smooth\"]])\n",
        "iot_df[\"humidity_scaled\"] = scaler.fit_transform(iot_df[[\"humidity_smooth\"]])\n",
        "\n",
        "# Encode sensor ID\n",
        "encoder = LabelEncoder()\n",
        "iot_df[\"sensor_encoded\"] = encoder.fit_transform(iot_df[\"sensor_id\"])\n",
        "\n",
        "print(\"\\n--- AFTER ---\")\n",
        "print(iot_df.head())\n",
        "\n",
        "# TESTS\n",
        "assert iot_df[\"temperature\"].isna().sum() == 0\n",
        "assert \"temp_scaled\" in iot_df.columns\n",
        "assert iot_df[\"sensor_encoded\"].nunique() > 0\n",
        "\n",
        "print(\"\\nTask 3 Passed All Tests ✔\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhJY0jat1T9i",
        "outputId": "d055887f-7961-4d88-e4a1-3192ed5bfe45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== TASK 3: IOT SENSOR ====================\n",
            "\n",
            "--- BEFORE ---\n",
            "             timestamp sensor_id  temperature  humidity\n",
            "0  2025-02-01 00:00:00        S2         24.0      40.0\n",
            "1  2025-02-01 01:00:00        S3         30.0       NaN\n",
            "2  2025-02-01 02:00:00        S1         24.0      50.0\n",
            "3  2025-02-01 03:00:00        S2         24.0       NaN\n",
            "4  2025-02-01 04:00:00        S3         23.0      42.0\n",
            "\n",
            "--- AFTER ---\n",
            "             timestamp sensor_id  temperature  humidity  temp_smooth  \\\n",
            "0  2025-02-01 00:00:00        S2         24.0      40.0         24.0   \n",
            "1  2025-02-01 01:00:00        S3         30.0      40.0         27.0   \n",
            "2  2025-02-01 02:00:00        S1         24.0      50.0         26.0   \n",
            "3  2025-02-01 03:00:00        S2         24.0      50.0         25.5   \n",
            "4  2025-02-01 04:00:00        S3         23.0      42.0         25.0   \n",
            "\n",
            "   humidity_smooth  temp_scaled  humidity_scaled  sensor_encoded  \n",
            "0        40.000000    -0.031984        -1.922355               1  \n",
            "1        40.000000     2.493079        -1.922355               2  \n",
            "2        43.333333     1.651391        -0.377054               0  \n",
            "3        45.000000     1.230547         0.395597               1  \n",
            "4        44.400000     0.809703         0.117443               2  \n",
            "\n",
            "Task 3 Passed All Tests ✔\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-91793892.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  iot_df[\"temperature\"] = iot_df[\"temperature\"].fillna(method=\"ffill\")\n",
            "/tmp/ipython-input-91793892.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  iot_df[\"humidity\"] = iot_df[\"humidity\"].fillna(method=\"ffill\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ---------------------- TASK 4 ----------------------------------\n",
        "# MOVIE REVIEWS\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n==================== TASK 4: MOVIE REVIEWS CLEANING ====================\")\n",
        "\n",
        "movie_df = pd.read_csv(\"movie_reviews-1.csv\")\n",
        "\n",
        "print(\"\\n--- BEFORE ---\")\n",
        "print(movie_df.head())\n",
        "\n",
        "# Clean HTML + lowercase\n",
        "def clean_review(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    return text.lower()\n",
        "\n",
        "movie_df[\"clean_review\"] = movie_df[\"review_text\"].apply(clean_review)\n",
        "\n",
        "# Tokenize + TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(movie_df[\"clean_review\"])\n",
        "\n",
        "# Rating → fill missing\n",
        "movie_df[\"rating\"] = movie_df[\"rating\"].fillna(movie_df[\"rating\"].median())\n",
        "\n",
        "# Normalize 0–10 → 0–1\n",
        "movie_df[\"rating_norm\"] = movie_df[\"rating\"] / 10\n",
        "\n",
        "print(\"\\n--- AFTER ---\")\n",
        "print(movie_df.head())\n",
        "\n",
        "# TESTS\n",
        "assert movie_df[\"clean_review\"].isna().sum() == 0\n",
        "assert movie_df[\"rating_norm\"].max() <= 1\n",
        "assert tfidf_matrix.shape[0] == len(movie_df)\n",
        "\n",
        "print(\"\\nTask 4 Passed All Tests ✔\")\n",
        "\n",
        "print(\"\\n==================== ALL TASKS COMPLETED SUCCESSFULLY ====================\\n\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adiz1SDT1ZsI",
        "outputId": "e12fa372-6ab7-47ba-bfe2-929a254791d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== TASK 4: MOVIE REVIEWS CLEANING ====================\n",
            "\n",
            "--- BEFORE ---\n",
            "   review_id                review_text  rating\n",
            "0          1      <p>Amazing movie!</p>     8.0\n",
            "1          2  Terrible acting & plot!!!     2.0\n",
            "2          3      <p>Amazing movie!</p>     NaN\n",
            "3          4  Terrible acting & plot!!!     8.0\n",
            "4          5      <p>Amazing movie!</p>     5.0\n",
            "\n",
            "--- AFTER ---\n",
            "   review_id                review_text  rating               clean_review  \\\n",
            "0          1      <p>Amazing movie!</p>     8.0             amazing movie!   \n",
            "1          2  Terrible acting & plot!!!     2.0  terrible acting & plot!!!   \n",
            "2          3      <p>Amazing movie!</p>     8.0             amazing movie!   \n",
            "3          4  Terrible acting & plot!!!     8.0  terrible acting & plot!!!   \n",
            "4          5      <p>Amazing movie!</p>     5.0             amazing movie!   \n",
            "\n",
            "   rating_norm  \n",
            "0          0.8  \n",
            "1          0.2  \n",
            "2          0.8  \n",
            "3          0.8  \n",
            "4          0.5  \n",
            "\n",
            "Task 4 Passed All Tests ✔\n",
            "\n",
            "==================== ALL TASKS COMPLETED SUCCESSFULLY ====================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}